\documentclass{standalone}

\begin{document}
	Correction Lin√©aire Automatique des Erreurs d'Arrondi (CENA) is a method for automatically compensating for rounding errors that result from elementary floating point operations. The method, also known as Automatic Linear Correction of Rounding Errors in English, was introduced by Philippe Langlois in $1999$ and a revised version was issued in $2001$. \cite{langlois2001automatic} The method utilizes the standard model of arithmetic along with the retrievable elementary error information to compute the global forward error of a computation and then correct the computed ``naive'' biased result.
	\subsection{The Method}
	Beginning with a motivating example, let $\hat{f}$ be the floating point evaluation of a real function $f$ at the points $X=(x_{1},\dots,x_{n})$ where intermediate variables $\hat{x}_{n+1},\dots,\hat{x}_{N-1}$ are computed to get the final results $\hat{x}_{N}$. \cite{langlois2001automatic} Then the global forward error is given by$$\hat{x}_{N}-f(X)=\Delta_{L}-E_{L}$$where ``$\Delta_{L}$ is the first-order approximate of the global rounding error with respect to the absolute elementary rounding errors $\delta=(\delta_{n+1},\dots,\delta_{N})$ generated by the computation of corresponding intermediate variables.'' \cite{langlois2001automatic} Then, $\Delta_{L}$ is given by$$\Delta_{L}=\sum_{k=n+1}^{N}\frac{\partial\hat{f}}{\partial\delta_{k}}(X,\delta)\cdot\delta_{k}$$and $E_{L}$ is the linearization error associated with the computation of $\Delta_{L}$. In practice, the computation of bounds for the global error can be too inaccurate or too large to be of any feasible use. Thus, Langlois presents ``a new differential method where the elementary rounding errors $\delta_{k}$'' are not bounded but instead computed. \cite{langlois2001automatic} CENA computes the global forward error with respect to the elementary rounding errors such that$$\bar{\Delta}_{L}=fl(\Delta_{L})$$and gives the following correction$$\bar{x}_{N}=fl(\hat{x}_{N}-\bar{\Delta}_{L}).$$As identified by Langlois, ``such a linear correction is particularly suitable when the global forward error is dominated by the first-order terms'' with linear algorithms such as Horner's method for polynomial evaluation, substitution algorithm for triangular systems and Newton's method for one-dimensional zero finding. In simple terms, the correction is the sum of $\delta_{k}$ generated by the intermediary operations $\hat{x}_{k}=fl(x_{i}\circ x_{j})$ when evaluating some function $\hat{f}$. The values of $\delta_{k}$ are computed using the EFTs and \texttt{ApproxTwoDiv} algorithms described above and upon computing $\hat{x}_{N}$, the result is corrected to get the result $\bar{x}_{N}$.
	It is also possible to correct the itermediate results when evaluating $\hat{f}$ if there is suspicion that there might be either catastrophic cancellation when evaluating $\bar{x}_{N}$ or an overaccumlation of rounding errors due to complex calculations. Correcting in such cases will lead to more accurate results compared to not correcting at all but these corrections may have arbitrarily bad accuracies with respect to the actual function value $f(X)$. \cite{langlois2001automatic} Thus, choosing intermediate results to correct throughout the computation of $\bar{x}_{N}$ is a viable strategy. 
	\subsection{Further Reading}
	Langlois also develops a methodology for implementing a automatic differentiation framework to automate the process of calculating elementary errors along with bounds related to the computation of the derivatives and certain confidence intervals. Further details of such bounds and refinements are out of the scope of this project but can be found in \cite{langlois2001automatic}, \cite{langlois2005solving} and \cite{graillat2009algorithms} and \cite{langlois2007ensure}.
\end{document}